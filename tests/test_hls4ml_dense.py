import os
from pathlib import Path

import pytest


def _require_vitis():
    if 'XILINX_VITIS' not in os.environ:
        pytest.skip('AMD Vitis not found (XILINX_VITIS not set)')


def _imports():
    np = pytest.importorskip('numpy')
    hls4ml = pytest.importorskip('hls4ml')
    keras = pytest.importorskip('keras')
    qkeras = pytest.importorskip('qkeras')
    return np, hls4ml, keras, qkeras


def _par_summary(layers):
    return '_'.join(f"{k}_c{v['cas_num']}x{v['cas_length']}" for k, v in layers.items())


def _build_qkeras_mlp(qkeras, input_shape, in_features, hidden1, hidden2, out_features, bits):
    from keras.models import Sequential
    from qkeras import QActivation, QDense, quantized_bits, quantized_relu

    assert int(input_shape[-1]) == int(in_features)

    INT_BITS = 2

    q_in = quantized_bits(bits, INT_BITS)
    q_w = quantized_bits(bits, 1, alpha=1)
    q_b = quantized_bits(bits, 1, alpha=1)

    model = Sequential(
        [
            QActivation(q_in, name='input_quant', input_shape=input_shape),
            QDense(hidden1, name='dense0', kernel_quantizer=q_w, bias_quantizer=q_b, bias_initializer='random_uniform'),
            QActivation(quantized_relu(bits, 0), name='act0'),
            QDense(hidden2, name='dense1', kernel_quantizer=q_w, bias_quantizer=q_b, bias_initializer='random_uniform'),
            QActivation(quantized_relu(bits, 0), name='act1'),
            QDense(
                out_features, name='dense2', kernel_quantizer=q_w, bias_quantizer=q_b, bias_initializer='random_uniform'
            ),
        ]
    )
    model.compile(optimizer='adam', loss='mse')
    return model


def _make_cfg(hls4ml, model, layer_parallelism):
    cfg = hls4ml.utils.config_from_keras_model(model, granularity='name')
    cfg.setdefault('LayerName', {})

    for lname, params in layer_parallelism.items():
        cfg['LayerName'].setdefault(lname, {})
        cfg['LayerName'][lname]['cas_num'] = int(params['cas_num'])
        cfg['LayerName'][lname]['cas_length'] = int(params['cas_length'])

    return cfg


def _make_aie_model(tmp_path, cfg_dict, input_shape):
    np, hls4ml, _keras, qkeras = _imports()

    qmodel = _build_qkeras_mlp(
        qkeras,
        input_shape=input_shape,
        in_features=384,
        hidden1=256,
        hidden2=200,
        out_features=10,
        bits=cfg_dict['bits'],
    )

    cfg = _make_cfg(hls4ml, qmodel, cfg_dict['layers'])

    tag = '1d' if len(input_shape) == 1 else f'nd{len(input_shape)}'
    outdir = tmp_path / (f"aie_mlp_b{cfg_dict['bits']}_bs{cfg_dict['batch']}_{_par_summary(cfg_dict['layers'])}_{tag}")

    aie_model = hls4ml.converters.convert_from_keras_model(
        qmodel,
        hls_config=cfg,
        output_dir=str(outdir),
        backend='aie',
        project_name='proj_aie',
        batch_size=cfg_dict['batch'],
        iterations=5,
    )

    return qmodel, aie_model


CFG_LIST = [
    {
        'bits': 8,
        'batch': 1,
        'layers': {
            'dense0': {'cas_num': 2, 'cas_length': 4},
            'dense1': {'cas_num': 1, 'cas_length': 4},
            'dense2': {'cas_num': 1, 'cas_length': 1},
        },
    },
    {
        'bits': 8,
        'batch': 10,
        'layers': {
            'dense0': {'cas_num': 2, 'cas_length': 4},
            'dense1': {'cas_num': 2, 'cas_length': 2},
            'dense2': {'cas_num': 1, 'cas_length': 2},
        },
    },
]


@pytest.mark.aie_ir
@pytest.mark.parametrize('cfg', CFG_LIST)
def test_aie_backend_conversion_only(tmp_path, cfg):
    """
    Conversion + lowering test.
    No Vitis required.
    """
    qmodel, aie_model = _make_aie_model(tmp_path, cfg, input_shape=(384,))
    assert aie_model is not None


@pytest.mark.aie_ir
@pytest.mark.requires_vitis
@pytest.mark.parametrize('cfg', CFG_LIST)
def test_aie_compile_x86_sim(tmp_path: Path, cfg: dict):
    """
    AIE backend + Vitis compile + x86 functional simulation.
    """
    _require_vitis()

    np, _hls4ml, _keras, _qkeras = _imports()
    qmodel, aie_model = _make_aie_model(tmp_path, cfg, input_shape=(384,))

    aie_model.compile()

    x = (np.random.random((cfg['batch'], 384)).astype('float32') * 2.0) - 1.0

    y_ref = qmodel.predict(x, verbose=0)
    y_aie = aie_model.predict(x, simulator='x86')

    y_aie = y_aie[: cfg['batch']]

    assert y_ref.shape == y_aie.shape
    np.testing.assert_equal(y_ref, y_aie)


@pytest.mark.aie_ir
@pytest.mark.requires_vitis
@pytest.mark.parametrize('input_shape', [(16, 384), (8, 16, 384)])
def test_aie_compile_x86_sim_nd_input(tmp_path: Path, input_shape):
    _require_vitis()
    np, hls4ml, keras, qkeras = _imports()

    from keras.models import Sequential
    from qkeras import QActivation, QDense, quantized_bits

    bits = 8
    B = 1
    N = 10

    q_w = quantized_bits(bits, 1, alpha=1)
    q_b = quantized_bits(bits, 1, alpha=1)

    qmodel = Sequential(
        [
            QActivation(quantized_bits(bits, 2), name='input_quant', input_shape=input_shape),
            QDense(
                N,
                name='dense0',
                kernel_quantizer=q_w,
                bias_quantizer=q_b,
                bias_initializer='random_uniform',
            ),
        ]
    )
    qmodel.compile(optimizer='adam', loss='mse')

    shape_tag = 'x'.join(str(d) for d in input_shape)
    outdir = tmp_path / f'aie_dense_nd_single_layer_{shape_tag}'
    aie_model = hls4ml.converters.convert_from_keras_model(
        qmodel,
        output_dir=str(outdir),
        backend='aie',
        project_name='proj_aie',
        batch_size=B,
        iterations=5,
    )

    # NOTE: keep this test relaxed. In the 2D Dense path, hls4ml may widen
    # inferred numeric types during parsing/lowering (e.g., 8-bit QKeras intent
    # leading to wider IO precision such as 16-bit in generated types).
    aie_model.compile()

    x = (np.random.random((B, *input_shape)).astype('float32') * 2.0) - 1.0
    y_ref = qmodel.predict(x, verbose=0)
    y_aie = aie_model.predict(x, simulator='x86')
    y_aie = y_aie[:B]

    assert y_ref.shape == y_aie.shape
    np.testing.assert_allclose(y_ref, y_aie, rtol=0.15, atol=0.15)


# Future TODO
#
# @pytest.mark.aie_ir
# @pytest.mark.requires_vitis
# @pytest.mark.slow
# def test_aie_build_and_hw_sim(...):
#     aie_model.build()
#
